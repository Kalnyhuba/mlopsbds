{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hubak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/556181\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name='bitcoin_price_movement_training_fv',\n",
    "    version=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_fg = fs.get_feature_group(\n",
    "    name='bitcoin_price_movement',\n",
    "    version=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bitcoin_fg.select_all()\n",
    "version = 2\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='bitcoin_price_movement_training_fv',\n",
    "    version=version,\n",
    "    query=data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (1.38s) \n"
     ]
    }
   ],
   "source": [
    "df = feature_view.get_batch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>ma7</th>\n",
       "      <th>ma21</th>\n",
       "      <th>bollinger_upper</th>\n",
       "      <th>bollinger_lower</th>\n",
       "      <th>lag7</th>\n",
       "      <th>volatility</th>\n",
       "      <th>close_usd_index</th>\n",
       "      <th>close_oil</th>\n",
       "      <th>close_gold</th>\n",
       "      <th>hash_rate</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2015-01-24 00:00:00+00:00</td>\n",
       "      <td>232.699997</td>\n",
       "      <td>248.210007</td>\n",
       "      <td>230.022003</td>\n",
       "      <td>247.847000</td>\n",
       "      <td>24782500</td>\n",
       "      <td>225.363429</td>\n",
       "      <td>242.852998</td>\n",
       "      <td>312.179592</td>\n",
       "      <td>173.526404</td>\n",
       "      <td>199.259995</td>\n",
       "      <td>13.918947</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>45.590000</td>\n",
       "      <td>1292.599976</td>\n",
       "      <td>264487.024401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>2015-01-25 00:00:00+00:00</td>\n",
       "      <td>247.352005</td>\n",
       "      <td>255.074005</td>\n",
       "      <td>243.889999</td>\n",
       "      <td>253.718002</td>\n",
       "      <td>33582700</td>\n",
       "      <td>231.560429</td>\n",
       "      <td>242.354093</td>\n",
       "      <td>311.184643</td>\n",
       "      <td>173.523543</td>\n",
       "      <td>210.339005</td>\n",
       "      <td>15.662329</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>45.590000</td>\n",
       "      <td>1292.599976</td>\n",
       "      <td>264487.024401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>2015-01-26 00:00:00+00:00</td>\n",
       "      <td>254.078995</td>\n",
       "      <td>309.384003</td>\n",
       "      <td>254.078995</td>\n",
       "      <td>273.472992</td>\n",
       "      <td>106794000</td>\n",
       "      <td>239.933572</td>\n",
       "      <td>242.306426</td>\n",
       "      <td>311.044877</td>\n",
       "      <td>173.567976</td>\n",
       "      <td>214.860992</td>\n",
       "      <td>20.243832</td>\n",
       "      <td>94.800003</td>\n",
       "      <td>45.150002</td>\n",
       "      <td>1279.400024</td>\n",
       "      <td>264487.024401</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>2015-01-27 00:00:00+00:00</td>\n",
       "      <td>273.166992</td>\n",
       "      <td>275.480011</td>\n",
       "      <td>250.653000</td>\n",
       "      <td>263.475006</td>\n",
       "      <td>44399000</td>\n",
       "      <td>247.385001</td>\n",
       "      <td>241.224808</td>\n",
       "      <td>307.742075</td>\n",
       "      <td>174.707541</td>\n",
       "      <td>211.315002</td>\n",
       "      <td>17.346404</td>\n",
       "      <td>94.019997</td>\n",
       "      <td>46.230000</td>\n",
       "      <td>1291.699951</td>\n",
       "      <td>264487.024401</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>2015-01-28 00:00:00+00:00</td>\n",
       "      <td>263.351013</td>\n",
       "      <td>266.535004</td>\n",
       "      <td>227.046005</td>\n",
       "      <td>233.914993</td>\n",
       "      <td>44352200</td>\n",
       "      <td>248.387571</td>\n",
       "      <td>238.347569</td>\n",
       "      <td>300.285301</td>\n",
       "      <td>176.409837</td>\n",
       "      <td>226.897003</td>\n",
       "      <td>16.124688</td>\n",
       "      <td>94.470001</td>\n",
       "      <td>44.450001</td>\n",
       "      <td>1285.900024</td>\n",
       "      <td>324166.338972</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date        open        high         low  \\\n",
       "485  2015-01-24 00:00:00+00:00  232.699997  248.210007  230.022003   \n",
       "1156 2015-01-25 00:00:00+00:00  247.352005  255.074005  243.889999   \n",
       "1776 2015-01-26 00:00:00+00:00  254.078995  309.384003  254.078995   \n",
       "2062 2015-01-27 00:00:00+00:00  273.166992  275.480011  250.653000   \n",
       "3297 2015-01-28 00:00:00+00:00  263.351013  266.535004  227.046005   \n",
       "\n",
       "           close     volume         ma7        ma21  bollinger_upper  \\\n",
       "485   247.847000   24782500  225.363429  242.852998       312.179592   \n",
       "1156  253.718002   33582700  231.560429  242.354093       311.184643   \n",
       "1776  273.472992  106794000  239.933572  242.306426       311.044877   \n",
       "2062  263.475006   44399000  247.385001  241.224808       307.742075   \n",
       "3297  233.914993   44352200  248.387571  238.347569       300.285301   \n",
       "\n",
       "      bollinger_lower        lag7  volatility  close_usd_index  close_oil  \\\n",
       "485        173.526404  199.259995   13.918947        95.000000  45.590000   \n",
       "1156       173.523543  210.339005   15.662329        95.000000  45.590000   \n",
       "1776       173.567976  214.860992   20.243832        94.800003  45.150002   \n",
       "2062       174.707541  211.315002   17.346404        94.019997  46.230000   \n",
       "3297       176.409837  226.897003   16.124688        94.470001  44.450001   \n",
       "\n",
       "       close_gold      hash_rate  id  \n",
       "485   1292.599976  264487.024401   1  \n",
       "1156  1292.599976  264487.024401   2  \n",
       "1776  1279.400024  264487.024401   3  \n",
       "2062  1291.699951  264487.024401   4  \n",
       "3297  1285.900024  324166.338972   5  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "high_prices = sorted_df.loc[:, 'high'].values\n",
    "low_prices = sorted_df.loc[:, 'low'].values\n",
    "mid_prices = (high_prices + low_prices) / 2.0\n",
    "\n",
    "mid_price_changes = np.diff(mid_prices) / mid_prices[:-1] * 100\n",
    "mid_price_changes = np.insert(mid_price_changes, 0, 0)\n",
    "\n",
    "features = sorted_df[['volume', 'ma7', 'ma21', 'bollinger_upper', 'bollinger_lower', 'volatility', 'close_usd_index', 'close_oil', 'close_gold', 'hash_rate']].values\n",
    "feature_changes = np.diff(features, axis=0) / features[:-1] * 100\n",
    "feature_changes = np.insert(feature_changes, 0, 0, axis=0)\n",
    "\n",
    "combined_features = np.column_stack((mid_price_changes.reshape(-1, 1), feature_changes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 100\n",
    "sequence_data = []\n",
    "sequence_labels = []\n",
    "\n",
    "for i in range(len(combined_features) - sequence_length):\n",
    "    sequence_data.append(combined_features[i:i + sequence_length])\n",
    "    # Labels based on whether the next mid_price_change is positive (1) or negative (0)\n",
    "    sequence_labels.append(1 if mid_price_changes[i + sequence_length] > 0 else 0)\n",
    "\n",
    "sequence_data = np.array(sequence_data)\n",
    "sequence_labels = np.array(sequence_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "split_index = int(len(sequence_data) * 0.8)\n",
    "train_data = sequence_data[:split_index]\n",
    "train_labels = sequence_labels[:split_index]\n",
    "test_data = sequence_data[split_index:]\n",
    "test_labels = sequence_labels[split_index:]\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_data), torch.from_numpy(train_labels))\n",
    "test_data = TensorDataset(torch.from_numpy(test_data), torch.from_numpy(test_labels))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating LSTM model class, which defines the model's structure\n",
    "# We added dropout layer too, to try to tackle overfitting problem\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.fc(self.dropout(lstm_out[:, -1, :]))\n",
    "        return out\n",
    "\n",
    "# Setting the input size of the model to match the number of features\n",
    "# Setting the number of neurons (hidden size) to 50\n",
    "# Setting the size of the output to 1, indicating that we will predict a single value (increase or decrease of the price)\n",
    "input_size = combined_features.shape[1]\n",
    "hidden_size = 30\n",
    "output_size = 1\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size)\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Early stopping parameters, these are added because early stopping method can reduce the risk of overfitting\n",
    "# Early stopping stops the training process when the model's performance doesn't improve on a validation set anymore\n",
    "# The patience parameter tells us through how many epochs we wait for improvement. If no improvement can be seen after 10, the training stops\n",
    "# We track the loss of the model and stop when we don't see improvement on it\n",
    "patience = 10\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# We use Binary Cross Entropy Loss function and combine it with a sigmoid layer in one function, which is needed for the classification problem\n",
    "# We use Adam optimiser to adjust the parameters of the model to minimise loss during training\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (0 dirs, 5 files)... DONE\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(11, 30, batch_first=True)\n",
       "  (fc): Linear(in_features=30, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = mr.get_model(\n",
    "    name=\"bitcoin_price_movement_prediction_model_lstm\", \n",
    "    version=1\n",
    ")\n",
    "\n",
    "saved_model_dir = model.download()\n",
    "\n",
    "lstm_model = LSTMModel(input_size, hidden_size, output_size)\n",
    "lstm_model.load_state_dict(torch.load(saved_model_dir + \"/bitcoin_price_movement_prediction_lstm.pth\"))\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, label in data_loader:\n",
    "            data = data.float()\n",
    "            output = model(data)\n",
    "            predicted = torch.sigmoid(output).squeeze().tolist()\n",
    "            predictions.extend(predicted)\n",
    "            true_labels.extend(label.squeeze().tolist())\n",
    "\n",
    "    predictions = [1 if p >= 0.5 else 0 for p in predictions]\n",
    "    true_labels = [1 if a >= 0.5 else 0 for a in true_labels]\n",
    "\n",
    "    return predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.48      0.53       305\n",
      "           1       0.63      0.73      0.68       373\n",
      "\n",
      "    accuracy                           0.62       678\n",
      "   macro avg       0.61      0.61      0.60       678\n",
      "weighted avg       0.61      0.62      0.61       678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions, labels = predict(lstm_model, test_loader)\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "true_labels = np.array(labels)\n",
    "\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future Predictions for next 2 days: ['Decrease', 'Decrease']\n"
     ]
    }
   ],
   "source": [
    "# This function creates forecasted values into the future, based on the latest sequence\n",
    "# It outputs a prediction whether the price would increase or decrease in the given time steps ahead in the future\n",
    "def forecast(model, data, sequence_length, steps_ahead):\n",
    "    model.eval()\n",
    "\n",
    "    data = np.array(data)\n",
    "    \n",
    "    current_sequence = data[-sequence_length:].reshape(1, sequence_length, -1)\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(steps_ahead):\n",
    "            input_seq = torch.tensor(current_sequence, dtype=torch.float32)\n",
    "            \n",
    "            output = model(input_seq)\n",
    "            predicted_value = torch.sigmoid(output).item()\n",
    "            \n",
    "            predicted_class = 1 if predicted_value >= 0.5 else 0\n",
    "            \n",
    "            predictions.append(predicted_class)\n",
    "            \n",
    "            new_sequence = np.append(current_sequence[0, 1:, :], [[predicted_class] * current_sequence.shape[2]], axis=0)\n",
    "            current_sequence = new_sequence.reshape(1, sequence_length, -1)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# We use the forecast function on the combined dataset, for 2 days ahead in the future and print the predictions\n",
    "all_data = np.concatenate((train_data.tensors[0].numpy(), test_data.tensors[0].numpy())).reshape(-1, input_size)\n",
    "steps_ahead = 2\n",
    "future_predictions = forecast(lstm_model, all_data, sequence_length, steps_ahead)\n",
    "movement_interpretation = ['Increase' if pred == 1 else 'Decrease' for pred in future_predictions]\n",
    "\n",
    "print('Future Predictions for next 2 days:', movement_interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(prices, predictions, initial_capital=100000):\n",
    "    capital = initial_capital\n",
    "    bitcoin_holdings = 0\n",
    "    \n",
    "    for t in range(len(prices)):\n",
    "        if predictions[t] == 1:  # Model predicts price will go up\n",
    "            if bitcoin_holdings == 0:  # Buy Bitcoin if not holding\n",
    "                bitcoin_holdings = capital / prices[t]\n",
    "                capital = 0\n",
    "        elif predictions[t] == 0:  # Model predicts price will go down\n",
    "            if bitcoin_holdings > 0:  # Sell Bitcoin if holding\n",
    "                capital = bitcoin_holdings * prices[t]\n",
    "                bitcoin_holdings = 0\n",
    "                \n",
    "    # Calculate final value (if any Bitcoin left, convert to cash)\n",
    "    final_value = capital + bitcoin_holdings * prices[-1]\n",
    "    return final_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return on Investment (ROI): 16.05%\n",
      "Final capital after 30 days: $116047.41\n"
     ]
    }
   ],
   "source": [
    "initial_capital = 100000\n",
    "prices = sorted_df['close'].tail(30).to_numpy()  # Example prices\n",
    "example_predictions = predictions[-30:]  # Example predictions (1 for up, 0 for down)\n",
    "\n",
    "final_value = backtest_strategy(prices, example_predictions)\n",
    "roi = ((final_value - initial_capital) / initial_capital) * 100\n",
    "print(f\"Return on Investment (ROI): {roi:.2f}%\")\n",
    "print(f\"Final capital after 30 days: ${final_value:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
